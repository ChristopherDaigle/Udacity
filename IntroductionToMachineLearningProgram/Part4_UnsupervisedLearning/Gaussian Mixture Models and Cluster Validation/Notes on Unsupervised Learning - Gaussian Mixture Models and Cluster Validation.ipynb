{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models\n",
    "\n",
    "<img src='macro_gaus.png' width=600px>\n",
    "<img src='1D_gaus.png' width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Distributions (Normal)\n",
    "<img src='norm_dist.png' width=600px>\n",
    "<img src='gaus_dist1.png' width=600px>\n",
    "<img src='gaus_dist2.png' width=600px>\n",
    "<img src='gaus_dist3.png' width=600px>\n",
    "<img src='gaus_dist4.png' width=600px>\n",
    "\n",
    "__________\n",
    "\n",
    "## Gaussian Mixture Model (GMM) Clustering\n",
    "Combine both tests' data points as they are on the same scale (0-100) and we have mixed the gaussian distributions\n",
    "<img src='gaus_mix1.png' width=600px>\n",
    "* The distributions are preserved, but they do not make one Gaussian distribution, rather the mixing allows them to exist simultaneously in the same range\n",
    "* Without knowing which data points came from which distribution, the distributions can be infered and the points with the higher probability of belonging to one gaussian distribution in the mixture over another are predicted to be as such, assigned to the respective test\n",
    "> 1 Mix the data\n",
    "<img src='gaus_mix2.png' width=600px>\n",
    "> 2 Find the data's distribution as a whole\n",
    "<img src='gaus_mix3.png' width=600px>\n",
    "> 3 Determine the different distributions and assign the data points based to the distribution that the probability is highest they belong to\n",
    "<img src='gaus_mix4.png' width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Distribution | Two Dimensions\n",
    "<img src='gaus_2d1.png' width=900px>\n",
    "\n",
    "* Plotting the two scores against one another yeilds the above visualization\n",
    "\n",
    "> * Scatter in the middle\n",
    "> * Histograms at the top and side (revealing each follows a gaussian distribution)\n",
    "> * Orange \"+\" is the mean of each\n",
    "> * Circles are the standard deviations (just as before)\n",
    ">> * First circle contains 68% of the data\n",
    ">> * Second contains 95%\n",
    ">> * Third contains 99%\n",
    "\n",
    "**Note the two different mixes (total of 4 distributions**\n",
    "<img src='gaus_2d2.png' width=600px>\n",
    "**Combining them, we can infer their original lables**\n",
    "<img src='gaus_2d3.png' width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GMM for prediction - Expectation Maximization\n",
    "\n",
    "<img src='gaus_exp1.png' width=900px>\n",
    "\n",
    "* To begin, it is common to use K-Means first to distinguish what kind of clusters there may be and then determine the number of distributions for `Step 1: Initialize Gaussian Distributions`\n",
    "\n",
    "* `Step 1:` Initialize Gaussian Distributions by determining a mean and variance\n",
    "<img src='gaus_exp2.png' width=900px>\n",
    "\n",
    "\n",
    "* `Step 2:` Soft-cluster the Data Points (Expectation Step)\n",
    "<img src='gaus_exp3.png' width=900px>\n",
    "\n",
    "* `Step 3:` Re-Estimate Parameters of Gaussians Maximization Step\n",
    "<img src='gaus_exp4.png' width=900px>\n",
    "<img src='gaus_exp4a.png' width=900px>\n",
    "\n",
    "* `Step 4:` Evaluate log-likelihood\n",
    "> the higher this value, the more sure we are that this point is correctly classfied\n",
    "<img src='gaus_exp5.png' width=900px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing with SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, mixture\n",
    "#Load dataset\n",
    "X = datasets.load_iris().data[:10]\n",
    "\n",
    "# Specify the parameters for the clustering\n",
    "gmm = mixture.GaussianMixture(n_components=3)\n",
    "gmm.fit(X)\n",
    "clustering = gmm.predict(X)\n",
    "# \"Clustering\" now contains an array representing which each point belongs to:\n",
    "# [1 0 0 0 1 2 0 1 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM Overview\n",
    "Paper: [Nonparametric discovery of human routines from sensor data](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.681.3152&rep=rep1&type=pdf)\n",
    "\n",
    "Paper: [Application of the Gaussian mixture model in pulsar astronomy](https://arxiv.org/abs/1205.6221)\n",
    "\n",
    "Paper: [Speaker Verification Using Adapted Gaussian Mixture Models](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.338&rep=rep1&type=pdf)\n",
    "\n",
    "Paper: [Adaptive background mixture models for real-time tracking](http://www.ai.mit.edu/projects/vsam/Publications/stauffer_cvpr98_track.pdf)\n",
    "\n",
    "Video: https://www.youtube.com/watch?v=lLt9H6RFO6A\n",
    "\n",
    "<img src='gaus_overv.png' width=900px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
