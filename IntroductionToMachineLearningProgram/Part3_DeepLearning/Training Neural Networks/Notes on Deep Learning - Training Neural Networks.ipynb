{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of errors: two types\n",
    "\n",
    "1) Underfitting - Over simplifying the problem (error due to bias)\n",
    "\n",
    "2) Overfitting - Overly complicated (error due to variance)\n",
    "\n",
    "<img src='typesoferrors.png'>\n",
    "\n",
    "We can err on the side of overfitting though, and then compensate for the issues of over fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "<img src='epocherror.png'>\n",
    "\n",
    "<img src='modelcompgraph.png'>\n",
    "\n",
    "We do gradient descent until the testing error stops decreasing and starts to increase, and then we stop training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Regularization is the process of penalizing weights that reduce the error\n",
    "\n",
    "<img src='regularization.png'>\n",
    "\n",
    "**General guidelines for deciding between L1 and L2 regularization:**\n",
    "L1: we get sparse vectors (small weights go to zero, less features/dimensionality reduction)\n",
    "\n",
    "L2: we get vector with small and homogenous weights\n",
    "<img src='l1l2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Apply some probability that a certain node/activation will be left out of the neural net for both forward and backward propogation for each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Restart\n",
    "\n",
    "When using Gradient Descent, we may end up at a **local minima** given parameters such as step and start point\n",
    "\n",
    "We can avoid this to some degree, or increase the likelihood we find the **global minima** by employing *Random Restart*.\n",
    "\n",
    "<img src='RandomRestart.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing Gradient\n",
    "\n",
    "With the sigmoid activation function, the gradient is small. When we use it for gradient descent, multiplying each step to update our backpropogation means we end up with a tiny value. Essentially, we may never arrive at the bottom.\n",
    "\n",
    "<img src='VanGrad.png'>\n",
    "<img src='VanDes.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Activation Functions\n",
    "**Note on Images: Origin is 0, not 0.5**\n",
    "\n",
    "1) Hyperbolic Tangent:\n",
    "$$tanh(x) = \\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$$\n",
    "<img src='tanh.png'>\n",
    "\n",
    "2) ReLU (Rectified Linear Unit):\n",
    "$$ relu(x)= \\begin{cases} \n",
    "      x & x\\ge 0 \\\\\n",
    "      0 & x \\le 0\n",
    "   \\end{cases}$$\n",
    "<img src='relu.png'>\n",
    "\n",
    "Now, with these different activation functionnds, we get larger derivatives and thus allow us to do gradient descent:\n",
    "<img src='BackPwDiffAFct.png'>\n",
    "\n",
    "Here, we can see now a multi-layer perceptron with different activarion functions indicated in the nodes, particularly ReLU in the hidden layers. Notice, the sigmoid is still at the output. This is because we need a probability between zero and one at the end.\n",
    "<img src='MultLayerwDiffAct.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch vs Stochastic Gradient Descent\n",
    "\n",
    "1) Batch Gradient Descent: Take all of the data and run it through the entire NN (forward prop), find the predictions (output), calculate error (y-yhat), and then update weights (backprop)\n",
    "* Slow, computationally intensive\n",
    "\n",
    "2) Stochastic Gradient Descent: Take small subsets of the data and run it through the entire NN (forward prop), find the predictions (output), calculate error (y-yhat), calculate the gradient of the error function based on those points, and then update weights (backprop), and move one step in that direction, and then iterate for each subset\n",
    "* Depends on the data being well distributed to give us a good idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Decay\n",
    "\n",
    "A larger learning rate may end up in overshooting the minimum point while a small learning rate may make the model take a very long time\n",
    "\n",
    "<img src='BigSmallLearnRate.png'>\n",
    "\n",
    "We can also update the learning rate as the problem goes forward. Such that, if the gradient is steep we take big steps, but if it is flat we take small steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "\n",
    "Instead of only taking steps based on the gradient, include some parameter, $\\beta$, that continues the steps with \"momentum\".\n",
    "\n",
    "<img src='Momentum.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
